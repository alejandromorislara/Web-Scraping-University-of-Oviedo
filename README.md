Uniovi News Scraper Pipeline 📰A Python automation pipeline that scrapes weekly news from the University of Oviedo website, compiles them into Excel, emails the report, downloads associated images, and stores everything in a MySQL database.📋 Table of ContentsProject OverviewRepository StructureInstallation & SetupConfigurationUsageModule DescriptionsData FlowLicenseContact🚀 Project OverviewThis project automates end-to-end news collection from the University of Oviedo site:Scrape the latest week’s articles.Export them to an Excel file.Email the report to stakeholders.Download all inline images.Store both text data and images in a MySQL database.📂 Repository Structure.
├── credentials.py       # Configuration variables: paths, DB & email creds
├── functions.py         # WebScraper class: scrape & export to Excel
├── main.py              # Orchestrator: runs the full pipeline
├── message_inicial.py   # Initial GUI confirmation
├── url_to_image.py      # Image downloading module
├── BBDD.py              # MySQL database interaction (procedural)
├── BBDD_OOP.py          # MySQL database interaction (object-oriented)
├── correo.py            # Email sending module
└── README.md
⚙️ Installation & SetupClone the repogit clone https://github.com/alejandromorislara/uniovi-news-scraper.git
cd uniovi-news-scraper
Create & activate a virtual environmentpython3 -m venv venv
source venv/bin/activate
Install Python dependenciespip install selenium beautifulsoup4 pandas openpyxl mysql-connector-python
Download ChromeDriverEnsure chromedriver binary matches your Chrome version.Place it somewhere on your PATH or note its full path for the config.🛠️ ConfigurationEdit credentials.py and set:chrome_driver_path: full path to your ChromeDriver binaryurl: base URL of the news siteEmail settings: SMTP server, port, sender email, password, recipient listMySQL settings: host, port, user, password, database namepath_excel_noticias: output folder for Excel reportsdirectory_images: base folder for downloaded images▶️ UsageSimply run the orchestrator:python main.py
The pipeline will:Show an initial confirmation dialog (message_inicial.py).Scrape the last 7 days of news (functions.py).Save an Excel file named noticias_DD_MM_YYYY.xlsx.Email that file to configured recipients (correo.py).Download each article’s images to directory_images/YYYYMMDD/ (url_to_image.py).Insert records and blob-store images into MySQL (BBDD.py or BBDD_OOP.py).📦 Module Descriptionscredentials.py: Holds all configurable parameters and secrets (paths, URLs, credentials).functions.py: Defines the WebScraper class to navigate pages with Selenium, parse with BeautifulSoup, build a DataFrame, and export to Excel.main.py: Imports all modules, runs each step in sequence, and handles errors/logging.message_inicial.py: Pops up a simple GUI window (Tkinter) to confirm whether to start scraping.url_to_image.py: Reads the Excel, iterates over image URLs, downloads each, and renames files for DB insertion.BBDD.py & BBDD_OOP.py: Two approaches to load data into MySQL: procedural vs. object-oriented.correo.py: Finds the most recent Excel report, composes an email with attachment, and sends via SMTP.🔄 Data FlowScrape → Excel: functions.WebScraper.scrape() → DataFrame → to_excel()Excel → Email: correo.send_latest_report()Excel → Images: url_to_image.download_all()Excel & Images → MySQL:Text data: INSERT rowsBlob data: LOAD_FILE or parameterized BLOB upload📜 LicenseThis project is licensed under the MIT License. See LICENSE for details.✉️ ContactAuthor: Alejandro Morís LaraEmail: alejandro.moris@vumi.io
