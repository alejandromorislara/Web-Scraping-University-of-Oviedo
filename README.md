Uniovi News Scraper Pipeline ğŸ“°A Python automation pipeline that scrapes weekly news from the University of Oviedo website, compiles them into Excel, emails the report, downloads associated images, and stores everything in a MySQL database.ğŸ“‹ Table of ContentsProject OverviewRepository StructureInstallation & SetupConfigurationUsageModule DescriptionsData FlowLicenseContactğŸš€ Project OverviewThis project automates end-to-end news collection from the University of Oviedo site:Scrape the latest weekâ€™s articles.Export them to an Excel file.Email the report to stakeholders.Download all inline images.Store both text data and images in a MySQL database.ğŸ“‚ Repository Structure.
â”œâ”€â”€ credentials.py       # Configuration variables: paths, DB & email creds
â”œâ”€â”€ functions.py         # WebScraper class: scrape & export to Excel
â”œâ”€â”€ main.py              # Orchestrator: runs the full pipeline
â”œâ”€â”€ message_inicial.py   # Initial GUI confirmation
â”œâ”€â”€ url_to_image.py      # Image downloading module
â”œâ”€â”€ BBDD.py              # MySQL database interaction (procedural)
â”œâ”€â”€ BBDD_OOP.py          # MySQL database interaction (object-oriented)
â”œâ”€â”€ correo.py            # Email sending module
â””â”€â”€ README.md
âš™ï¸ Installation & SetupClone the repogit clone https://github.com/alejandromorislara/uniovi-news-scraper.git
cd uniovi-news-scraper
Create & activate a virtual environmentpython3 -m venv venv
source venv/bin/activate
Install Python dependenciespip install selenium beautifulsoup4 pandas openpyxl mysql-connector-python
Download ChromeDriverEnsure chromedriver binary matches your Chrome version.Place it somewhere on your PATH or note its full path for the config.ğŸ› ï¸ ConfigurationEdit credentials.py and set:chrome_driver_path: full path to your ChromeDriver binaryurl: base URL of the news siteEmail settings: SMTP server, port, sender email, password, recipient listMySQL settings: host, port, user, password, database namepath_excel_noticias: output folder for Excel reportsdirectory_images: base folder for downloaded imagesâ–¶ï¸ UsageSimply run the orchestrator:python main.py
The pipeline will:Show an initial confirmation dialog (message_inicial.py).Scrape the last 7 days of news (functions.py).Save an Excel file named noticias_DD_MM_YYYY.xlsx.Email that file to configured recipients (correo.py).Download each articleâ€™s images to directory_images/YYYYMMDD/ (url_to_image.py).Insert records and blob-store images into MySQL (BBDD.py or BBDD_OOP.py).ğŸ“¦ Module Descriptionscredentials.py: Holds all configurable parameters and secrets (paths, URLs, credentials).functions.py: Defines the WebScraper class to navigate pages with Selenium, parse with BeautifulSoup, build a DataFrame, and export to Excel.main.py: Imports all modules, runs each step in sequence, and handles errors/logging.message_inicial.py: Pops up a simple GUI window (Tkinter) to confirm whether to start scraping.url_to_image.py: Reads the Excel, iterates over image URLs, downloads each, and renames files for DB insertion.BBDD.py & BBDD_OOP.py: Two approaches to load data into MySQL: procedural vs. object-oriented.correo.py: Finds the most recent Excel report, composes an email with attachment, and sends via SMTP.ğŸ”„ Data FlowScrape â†’ Excel: functions.WebScraper.scrape() â†’ DataFrame â†’ to_excel()Excel â†’ Email: correo.send_latest_report()Excel â†’ Images: url_to_image.download_all()Excel & Images â†’ MySQL:Text data: INSERT rowsBlob data: LOAD_FILE or parameterized BLOB uploadğŸ“œ LicenseThis project is licensed under the MIT License. See LICENSE for details.âœ‰ï¸ ContactAuthor: Alejandro MorÃ­s LaraEmail: alejandro.moris@vumi.io
